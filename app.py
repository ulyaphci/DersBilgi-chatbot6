# app.py
import streamlit as st
import pandas as pd
import nltk
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.corpus import stopwords
import re
from datetime import datetime

# NLTK setup (only stopwords now)
nltk_data_dir = os.path.join(os.getcwd(), "nltk_data")
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

try:
    nltk.data.find("corpora/stopwords")
except LookupError:
    nltk.download("stopwords", download_dir=nltk_data_dir)

# Load Excel data
column_names = [
    "sÄ±nÄ±f", "ders_adÄ±", "hoca-adÄ±", "gÃ¼n1", "saat1", "derslik1",
    "gÃ¼n2", "saat2", "derslik2", "vizetarihi", "saat.1",
    "finaltarihi", "saat.2", "butunlemetarihi", "saat.3"
]
df = pd.read_excel("ders_bilgi.xlsx", names=column_names, header=1)

# Preprocessing
stop_words = set(stopwords.words("turkish"))

def preprocess_text(text):
    tokens = re.findall(r'\b\w+\b', str(text).lower())
    return " ".join([w for w in tokens if w not in stop_words])

df["document"] = df.apply(lambda row: f"{row['sÄ±nÄ±f']} {row['ders_adÄ±']} {row['hoca-adÄ±']} "
                                      f"{row['gÃ¼n1']} {row['saat1']} {row['derslik1']} "
                                      f"{row['gÃ¼n2']} {row['saat2']} {row['derslik2']} "
                                      f"{row['vizetarihi']} {row['saat.1']} "
                                      f"{row['finaltarihi']} {row['saat.2']} "
                                      f"{row['butunlemetarihi']} {row['saat.3']}", axis=1)

df["processed"] = df["document"].apply(preprocess_text)

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df["processed"])

def find_best_match(user_input):
    processed_input = preprocess_text(user_input)
    user_vec = vectorizer.transform([processed_input])
    similarities = cosine_similarity(user_vec, tfidf_matrix)
    best_idx = similarities.argmax()
    return df.iloc[best_idx]

def extract_info(question, row):
    q = question.lower()

    if re.search(r'\b(selam|merhaba|gÃ¼naydÄ±n|iyi akÅŸamlar|nasÄ±lsÄ±n)\b', q):
        return "Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ˜Š"

    if "final" in q:
        return f"{row['ders_adÄ±']} dersi finali: {row['finaltarihi']} Saat: {row['saat.2']}"
    if "vize" in q:
        return f"{row['ders_adÄ±']} dersi vizesi: {row['vizetarihi']} Saat: {row['saat.1']}"
    if "bÃ¼t" in q or "bÃ¼tÃ¼nleme" in q:
        return f"{row['ders_adÄ±']} dersi bÃ¼tÃ¼nlemesi: {row['butunlemetarihi']} Saat: {row['saat.3']}"

    sinif_match = re.search(r'(\d)\.?\s*sÄ±nÄ±f', q)
    if "hangi sÄ±nÄ±f" in q or "kaÃ§Ä±ncÄ± sÄ±nÄ±f" in q:
        return f"{row['ders_adÄ±']} dersi {row['sÄ±nÄ±f']}. sÄ±nÄ±f dersidir."
    elif sinif_match:
        sinif = int(sinif_match.group(1))
        dersler = df[df["sÄ±nÄ±f"] == sinif]["ders_adÄ±"].unique()
        return f"{sinif}. sÄ±nÄ±f dersleri:\n" + "\n".join(f"- {d}" for d in dersler)

    gunler = ["pazartesi", "salÄ±", "Ã§arÅŸamba", "perÅŸembe", "cuma"]
    for gun in gunler:
        if gun in q:
            if sinif_match:
                sinif = int(sinif_match.group(1))
                dersler = df[((df["gÃ¼n1"].str.lower() == gun) | (df["gÃ¼n2"].str.lower() == gun)) & (df["sÄ±nÄ±f"] == sinif)]
            else:
                dersler = df[(df["gÃ¼n1"].str.lower() == gun) | (df["gÃ¼n2"].str.lower() == gun)]
            if not dersler.empty:
                return f"{gun.capitalize()} gÃ¼nÃ¼ dersler:\n" + "\n".join(f"- {d}" for d in dersler["ders_adÄ±"].unique())
            return f"{gun.capitalize()} gÃ¼nÃ¼ iÃ§in ders bulunamadÄ±."

    if "bugÃ¼n" in q:
        weekday = datetime.today().strftime("%A").lower()
        gun_map = {"monday": "pazartesi", "tuesday": "salÄ±", "wednesday": "Ã§arÅŸamba",
                   "thursday": "perÅŸembe", "friday": "cuma"}
        gun = gun_map.get(weekday, "")
        dersler = df[(df["gÃ¼n1"].str.lower() == gun) | (df["gÃ¼n2"].str.lower() == gun)]
        return f"BugÃ¼n ({gun}) olan dersler:\n" + "\n".join(f"- {d}" for d in dersler["ders_adÄ±"].unique()) if not dersler.empty else "BugÃ¼n ders yok."

    if "derslik" in q or "nerede" in q:
        return f"{row['ders_adÄ±']} dersi:\n- {row['gÃ¼n1']}: {row['derslik1']}\n- {row['gÃ¼n2']}: {row['derslik2']}"

    for hoca in df["hoca-adÄ±"].dropna().unique():
        ad = hoca.split()[0].lower()
        if ad in q:
            hoca_dersleri = df[df["hoca-adÄ±"].str.lower().str.contains(ad)]["ders_adÄ±"].unique()
            return f"{hoca} hocanÄ±n verdiÄŸi dersler:\n" + "\n".join(f"- {d}" for d in hoca_dersleri)

    date_match = re.search(r"\d{2}\.\d{2}\.\d{4}", question)
    if date_match:
        date_str = date_match.group()
        matched_rows = df[
            (df["vizetarihi"].astype(str) == date_str) |
            (df["finaltarihi"].astype(str) == date_str) |
            (df["butunlemetarihi"].astype(str) == date_str)
        ]
        if not matched_rows.empty:
            response = f"{date_str} tarihinde yapÄ±lan sÄ±nav(lar):\n"
            for _, r in matched_rows.iterrows():
                if str(r["vizetarihi"]) == date_str:
                    response += f"- {r['ders_adÄ±']} (Vize)\n"
                if str(r["finaltarihi"]) == date_str:
                    response += f"- {r['ders_adÄ±']} (Final)\n"
                if str(r["butunlemetarihi"]) == date_str:
                    response += f"- {r['ders_adÄ±']} (BÃ¼tÃ¼nleme)\n"
            return response
        return f"{date_str} tarihinde herhangi bir sÄ±nav bulunamadÄ±."

    return f"{row['ders_adÄ±']} dersi hakkÄ±nda bilgi: {row['sÄ±nÄ±f']}. sÄ±nÄ±f, Vize: {row['vizetarihi']}, Final: {row['finaltarihi']}"

# Streamlit UI
st.title("ğŸ“š Ders Bilgi Chatbotu")

if "history" not in st.session_state:
    st.session_state.history = []

user_input = st.chat_input("Sorunuzu yazÄ±nÄ±z...")

if user_input:
    st.session_state.history.append(("user", user_input))
    match_row = find_best_match(user_input)
    response = extract_info(user_input, match_row)
    st.session_state.history.append(("assistant", response))

for role, message in st.session_state.history:
    with st.chat_message(role):
        st.markdown(message)
